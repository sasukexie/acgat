#* general
gpu_id: '0'
use_gpu: True
seed: 2021
state: INFO
reproducibility: True
checkpoint_dir: 'saved/dataset'
show_progress: True
save_dataloaders: True
log_root: "./log/"
worker: 0                       # (int) The number of workers processing the data.
save_dataset: True             # (bool) Whether or not to save filtered dataset.
dataset_save_path: ~            # (str) The path of saved dataset.
dataloaders_save_path: ~        # (str) The path of saved dataloaders.
log_wandb: False                # (bool) Whether or not to use Weights & Biases(W&B).
wandb_project: 'recbole'        # (str) The project to conduct experiments in W&B.
shuffle: True                   # (bool) Whether or not to shuffle the training data before each epoch.

#* dataset
data_path: "./dataset/"
#指定从什么文件里读什么列，这里就是从ml-1m.inter里面读取user_id, item_id, rating, timestamp这四列,剩下的以此类推
field_separator: "\t" #指定数据集field的分隔符
seq_separator: " " #指定数据集中token_seq或者float_seq域里的分隔符
USER_ID_FIELD: user_id #指定用户id域
ITEM_ID_FIELD: item_id #指定物品id域
RATING_FIELD: rating #指定打分rating域
TIME_FIELD: timestamp #指定时间域
USER_ACTIVITY_FIELD: user_activity #指定时间域
use_source_data: False # True 使用原始数据, ml-100k, 不使用原始数据, 则使用dataset目录下数据
load_col:
    inter: ['user_id', 'item_id', 'rating', 'timestamp']
# threshold:
#    rating: 4 #[4,∞), 未设置则全部交互都为正样本

#neg_sampling: # 负采样
#  uniform: 1
NEG_PREFIX: neg_ #指定负采样前缀
LABEL_FIELD: label #指定标签域
ITEM_LIST_LENGTH_FIELD: item_length #指定序列长度域
LIST_SUFFIX: _list #指定序列前缀
MAX_ITEM_LIST_LENGTH: 50 #指定最大序列长度
POSITION_FIELD: position_id #指定生成的序列位置id

#user_inter_num_interval: [0,inf)
#lowest_val:
#    timestamp: 1546264800
#highest_val:
#    timestamp: 1577714400

#* training settings
epochs: 100 #训练的最大轮数
train_batch_size: 1024 #训练的batch_size
learner: adam #使用的pytorch内置优化器
learning_rate: 0.001 #学习率
training_neg_sample_num: 0 #负采样数目
eval_step: 1 #每次训练后做evalaution的次数
stopping_step: 10 #10,100 #控制训练收敛的步骤数，在该步骤数内若选取的评测标准没有什么变化，就可以提前停止了
log_interval: 10  # Number of iterations between logs
fast_sample_eval: 1
clip_grad_norm: ~               # (dict) The args of clip_grad_norm_ which will clip gradient norm of model.
require_pow: False              # (bool) Whether or not to perform power operation in EmbLoss.
enable_amp: False               # (bool) Whether or not to use mixed precision training.
enable_scaler: False            # (bool) Whether or not to use GradScaler in mixed precision training.
transform: ~                    # (str) The transform operation for batch data process.


#* evalution settings
eval_setting: TO_LS,full #对数据按时间排序，设置留一法划分数据集，并使用全排序
metrics: ["Recall","NDCG","GAUC","Hit","MRR","Precision"] #评测标准["Recall","NDCG","GAUC","Hit","MRR","Precision"]
topk: [1, 5, 10, 15, 20, 50]
valid_metric: Recall@10 #选取哪个评测标准作为作为提前停止训练的标准
eval_batch_size: 1024 #评测的batch_size
weight_decay: 0
eval_args: # 不同模型,需要用一样的eval参数,不然会不公平
  split: {'RS':[0.8,0.1,0.1]} # {'LS':[0.8,0.1,0.1]} # LS: 留一法,留下最后一个item做测试,倒数第二个item做验证
  group_by: user # 对每个user执行LS
  order: RO # RS:TO 时间顺序,GNN:RO 随机顺序
  mode: full
repeatable: True
loss_decimal_place: 4
metric_decimal_place: 4
valid_metric_bigger: True       # (bool) Whether to take a bigger valid metric value as a better result.
